# ãƒ•ã‚¡ã‚¤ãƒ«å: rdd_per_release_final.py

import mysql.connector
import pandas as pd
from mysql.connector import Error
import matplotlib.pyplot as plt
import statsmodels.api as sm
from dateutil.relativedelta import relativedelta
import os

# --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæƒ…å ± (â˜…ã”è‡ªèº«ã®ç’°å¢ƒã«åˆã‚ã›ã¦ä¿®æ­£ã—ã¦ãã ã•ã„) ---
DB_CONFIG = {
    'host': 'mussel.naist.jp',
    'port': 3306,
    'user': 'root',
    'password': 'hoge',
}

# --- åˆ†æå¯¾è±¡ã®å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å®šç¾© ---
STUDY_PROJECTS = [
    {
        'project_name': 'JDT.CORE',
        'schema': 'eclipse_check',
        'releases': {
            'LR': {'start_date': '2016-06-22', 'end_date': '2018-06-26'},
            'SR': {'start_date': '2018-06-27', 'end_date': '2020-06-16'}
        },
        'historical_releases': [
            # --- LR (Annual Releases) ---
            {'date': '2016-06-22', 'type': 'LR'},  # Neon
            {'date': '2017-06-28', 'type': 'LR'},  # Oxygen
            # --- SR (Quarterly Releases) ---
            {'date': '2018-06-27', 'type': 'SR'},  # Photon (Transition point)
            {'date': '2018-09-19', 'type': 'SR'},  # 2018-09
            {'date': '2018-12-19', 'type': 'SR'},  # 2018-12
            {'date': '2019-03-20', 'type': 'SR'},  # 2019-03
            {'date': '2019-06-19', 'type': 'SR'},  # 2019-06
            {'date': '2019-09-18', 'type': 'SR'},  # 2019-09
            {'date': '2019-12-18', 'type': 'SR'},  # 2019-12
            {'date': '2020-03-18', 'type': 'SR'},  # 2020-03
        ]
    },
    {
        'project_name': 'PLATFORM.SWT',
        'schema': 'eclipse_check_swt',
        'releases': {
            'LR': {'start_date': '2016-06-22', 'end_date': '2018-06-26'},
            'SR': {'start_date': '2018-06-27', 'end_date': '2020-06-16'}
        },
        'historical_releases': [
            {'date': '2016-06-22', 'type': 'LR'}, {'date': '2017-06-28', 'type': 'LR'},
            {'date': '2018-06-27', 'type': 'SR'}, {'date': '2018-09-19', 'type': 'SR'},
            {'date': '2018-12-19', 'type': 'SR'}, {'date': '2019-03-20', 'type': 'SR'},
            {'date': '2019-06-19', 'type': 'SR'}, {'date': '2019-09-18', 'type': 'SR'},
            {'date': '2019-12-18', 'type': 'SR'}, {'date': '2020-03-18', 'type': 'SR'},
        ]
    },
    {
        'project_name': 'PLATFORM.UI',
        'schema': 'eclipse_check_ui',
        'releases': {
            'LR': {'start_date': '2016-06-22', 'end_date': '2018-06-26'},
            'SR': {'start_date': '2018-06-27', 'end_date': '2020-06-16'}
        },
        'historical_releases': [
            {'date': '2016-06-22', 'type': 'LR'}, {'date': '2017-06-28', 'type': 'LR'},
            {'date': '2018-06-27', 'type': 'SR'}, {'date': '2018-09-19', 'type': 'SR'},
            {'date': '2018-12-19', 'type': 'SR'}, {'date': '2019-03-20', 'type': 'SR'},
            {'date': '2019-06-19', 'type': 'SR'}, {'date': '2019-09-18', 'type': 'SR'},
            {'date': '2019-12-18', 'type': 'SR'}, {'date': '2020-03-18', 'type': 'SR'},
        ]
    },
    # --- ã“ã“ã«æ–°ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿½åŠ ã—ã¾ã—ãŸ ---
    {
        'project_name': 'PDE',
        'schema': 'eclipse_check_pde',
        'releases': {
            'LR': {'start_date': '2016-06-22', 'end_date': '2018-06-26'},
            'SR': {'start_date': '2018-06-27', 'end_date': '2020-06-16'}
        },
        'historical_releases': [
            # --- LR (Annual Releases) ---
            {'date': '2016-06-22', 'type': 'LR'},  # Neon
            {'date': '2017-06-28', 'type': 'LR'},  # Oxygen
            # --- SR (Quarterly Releases) ---
            {'date': '2018-06-27', 'type': 'SR'},  # Photon (Transition point)
            {'date': '2018-09-19', 'type': 'SR'},  # 2018-09
            {'date': '2018-12-19', 'type': 'SR'},  # 2018-12
            {'date': '2019-03-20', 'type': 'SR'},  # 2019-03
            {'date': '2019-06-19', 'type': 'SR'},  # 2019-06
            {'date': '2019-09-18', 'type': 'SR'},  # 2019-09
            {'date': '2019-12-18', 'type': 'SR'},  # 2019-12
            {'date': '2020-03-18', 'type': 'SR'},  # 2020-03
        ]
    },
    # ------------------------------------
    {
        'project_name': 'Firefox Transition (LR vs SR)',
        'schema': 'firefox_check',
        'releases': {
            'LR': {'start_date': '2009-10-24', 'end_date': '2011-03-21'},
            'SR': {'start_date': '2011-03-22', 'end_date': '2013-03-21'}
        },
        'historical_releases': [
            {'date': '2006-10-24', 'type': 'LR'}, {'date': '2008-06-17', 'type': 'LR'},
            {'date': '2009-06-30', 'type': 'LR'}, {'date': '2010-01-21', 'type': 'LR'},
            {'date': '2011-03-22', 'type': 'SR'}, {'date': '2011-06-21', 'type': 'SR'},
            {'date': '2011-08-16', 'type': 'SR'}, {'date': '2011-09-27', 'type': 'SR'},
            {'date': '2011-11-08', 'type': 'SR'}, {'date': '2011-12-20', 'type': 'SR'},
            {'date': '2012-01-31', 'type': 'SR'}, {'date': '2012-03-13', 'type': 'SR'},
            {'date': '2012-04-24', 'type': 'SR'}, {'date': '2012-06-05', 'type': 'SR'},
            {'date': '2012-07-17', 'type': 'SR'}, {'date': '2012-08-28', 'type': 'SR'},
            {'date': '2012-10-09', 'type': 'SR'}, {'date': '2012-11-20', 'type': 'SR'},
            {'date': '2013-01-08', 'type': 'SR'}, {'date': '2013-02-19', 'type': 'SR'},
        ]
    },
    {
        'project_name': 'Firefox 57-96',
        'schema': 'firefox_check',
        'releases': {
            'LR': {'start_date': '2017-11-14', 'end_date': '2019-12-02'},
            'SR': {'start_date': '2019-12-03', 'end_date': '2022-01-11'}
        }
    }
]


def fetch_and_prepare_data(db_conn, project_info):
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€é€±æ¬¡ã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«æ•´å½¢ã™ã‚‹ã€‚
    """
    schema = project_info['schema']
    project_name = project_info['project_name']

    print(f"Fetching data for {project_name} using the specified schema logic...")

    # SQLã‚¯ã‚¨ãƒª: SATD, Commits, SATDInFileã‚’JOINã—ã¦SATDã‚¤ãƒ™ãƒ³ãƒˆã®æ—¥æ™‚ã‚’å–å¾—
    query_satd_events = f"""
    SELECT
        C.commit_date,
        S.resolution AS change_type
    FROM {schema}.SATD AS S
    INNER JOIN {schema}.Commits AS C ON S.second_commit = C.commit_hash
    INNER JOIN {schema}.SATDInFile AS F ON S.second_file = F.f_id
    WHERE S.resolution IN ('SATD_ADDED', 'SATD_REMOVED')
      AND F.f_comment NOT LIKE '%Copyright@%';
    """

    # SQLã‚¯ã‚¨ãƒª: æ­£è¦åŒ–ã®ãŸã‚ã«å…¨ã¦ã®ã‚³ãƒŸãƒƒãƒˆæ—¥æ™‚ã‚’å–å¾—
    query_all_commits = f"""
    SELECT commit_hash, commit_date FROM {schema}.Commits;
    """

    try:
        # 1. SATDã‚¤ãƒ™ãƒ³ãƒˆï¼ˆè¿½åŠ ã¨é™¤å»ï¼‰ã®ãƒªã‚¹ãƒˆã‚’æ—¥ä»˜ä»˜ãã§å–å¾—
        satd_events_df = pd.read_sql_query(query_satd_events, db_conn)
        satd_events_df['date'] = pd.to_datetime(satd_events_df['commit_date'])

        # 2. æ—¥ä»˜ã¨å¤‰æ›´ã‚¿ã‚¤ãƒ—ã‚’å…ƒã«ã‚¯ãƒ­ã‚¹é›†è¨ˆã—ã€é€±ã”ã¨ã®ã‚¤ãƒ™ãƒ³ãƒˆæ•°ã‚’è¨ˆç®—
        satd_counts_df = pd.crosstab(index=satd_events_df['date'], columns=satd_events_df['change_type'])
        weekly_satd_df = satd_counts_df.resample('W-MON').sum()

        # ã‚¤ãƒ™ãƒ³ãƒˆãŒç™ºç”Ÿã—ãªã‹ã£ãŸå ´åˆã«å‚™ãˆã€ã‚«ãƒ©ãƒ ã‚’ç¢ºä¿
        if 'SATD_ADDED' not in weekly_satd_df: weekly_satd_df['SATD_ADDED'] = 0
        if 'SATD_REMOVED' not in weekly_satd_df: weekly_satd_df['SATD_REMOVED'] = 0

        # RDDåˆ†æé–¢æ•°ãŒæœŸå¾…ã™ã‚‹ã‚«ãƒ©ãƒ åã«å¤‰æ›´
        weekly_satd_df.rename(columns={'SATD_ADDED': 'ADDED', 'SATD_REMOVED': 'REMOVED'}, inplace=True)

        # 3. æ­£è¦åŒ–ã®ãŸã‚ã€é€±ã”ã¨ã®ç·ã‚³ãƒŸãƒƒãƒˆæ•°ã‚’è¨ˆç®—
        all_commits_df = pd.read_sql_query(query_all_commits, db_conn)
        all_commits_df['date'] = pd.to_datetime(all_commits_df['commit_date'])
        weekly_commits_count = all_commits_df.set_index('date')['commit_hash'].resample('W-MON').count()
        weekly_commits_count.name = "total_commits"

        # 4. SATDæ•°ã¨ç·ã‚³ãƒŸãƒƒãƒˆæ•°ã‚’çµåˆ
        final_df = weekly_satd_df.join(weekly_commits_count, how='outer').fillna(0)

        # 5. æ­£è¦åŒ–ï¼ˆ100ã‚³ãƒŸãƒƒãƒˆã‚ãŸã‚Šã®SATDæ•°ï¼‰
        final_df['Normalized_ADDED'] = (final_df['ADDED'] / final_df['total_commits']).where(
            final_df['total_commits'] > 0, 0) * 100
        final_df['Normalized_REMOVED'] = (final_df['REMOVED'] / final_df['total_commits']).where(
            final_df['total_commits'] > 0, 0) * 100

        print("Data preparation complete.")
        return final_df.reset_index()

    except Error as e:
        print(f"âŒ SQL Error during data fetching for {project_name}: {e}")
        print("ğŸ‘‰ ã‚¯ã‚¨ãƒªå†…ã®ãƒ†ãƒ¼ãƒ–ãƒ«åã‚„ã‚«ãƒ©ãƒ åãŒã€å®Ÿéš›ã®ã‚¹ã‚­ãƒ¼ãƒã¨ä¸€è‡´ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return None
    except Exception as e:
        print(f"An unexpected error occurred during data preparation for {project_name}: {e}")
        return None


def generate_release_dates(project_info):
    """
    ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‹ã‚‰åˆ†æå¯¾è±¡ã¨ãªã‚‹ãƒ¡ã‚¸ãƒ£ãƒ¼ãƒªãƒªãƒ¼ã‚¹æ—¥ã®ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    release_dates = []
    project_name = project_info['project_name']

    # historical_releasesãŒå®šç¾©ã•ã‚Œã¦ã„ã‚Œã°ã€ãã‚Œã‚’å„ªå…ˆçš„ã«ä½¿ç”¨
    if 'historical_releases' in project_info:
        print(f"Using historical release dates for {project_name}...")
        for d in project_info['historical_releases']:
            release_dates.append({'date': pd.to_datetime(d['date']), 'type': d['type']})
        return release_dates

    # (historical_releasesãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†)
    releases_info = project_info['releases']
    lr_delta, sr_delta = None, None
    if 'Firefox 57-96' in project_name:
        print("Applying special release cycle for Firefox 57-96 (LR: 6 weeks, SR: 4 weeks)...")
        lr_delta, sr_delta = relativedelta(weeks=6), relativedelta(weeks=4)
    else:
        print("Applying standard Eclipse release cycle...")
        lr_delta, sr_delta = relativedelta(years=1), relativedelta(months=4)

    if lr_delta:
        lr_info = releases_info['LR']
        current_release = pd.to_datetime(lr_info['start_date']) + lr_delta
        while current_release <= pd.to_datetime(lr_info['end_date']):
            release_dates.append({'date': current_release, 'type': 'LR'})
            current_release += lr_delta

    if sr_delta:
        sr_info = releases_info['SR']
        current_release = pd.to_datetime(sr_info['start_date']) + sr_delta
        while current_release <= pd.to_datetime(sr_info['end_date']):
            release_dates.append({'date': current_release, 'type': 'SR'})
            current_release += sr_delta

    return release_dates


def perform_rdd_analysis_for_release(df, project_name, release_info, outcome_variable, window_weeks=104):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒªãƒªãƒ¼ã‚¹æ—¥ã‚’å¢ƒç•Œã¨ã—ã¦RDDåˆ†æã‚’å®Ÿè¡Œã—ã€çµæœã¨ãƒ—ãƒ­ãƒƒãƒˆã‚’ä¿å­˜ã™ã‚‹ã€‚
    """
    release_date = release_info['date']
    release_type = release_info['type']
    release_date_str = release_date.strftime('%Y-%m-%d')
    print(
        f"\n--- Performing RDD Analysis for {project_name} ({outcome_variable}) around {release_date_str} ({release_type}) ---")

    # åˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆãƒªãƒªãƒ¼ã‚¹å‰å¾Œ2å¹´ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    start_date = release_date - pd.Timedelta(weeks=window_weeks)
    end_date = release_date + pd.Timedelta(weeks=window_weeks)
    rdd_df = df[(df['date'] >= start_date) & (df['date'] <= end_date)].copy()

    if len(rdd_df) < 20:  # åˆ†æã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ç¢ºèª
        print("Not enough data points within the window to perform analysis.")
        return None

    # RDDãƒ¢ãƒ‡ãƒ«ã®å¤‰æ•°ã‚’æº–å‚™
    rdd_df['time_from_cutoff'] = (rdd_df['date'] - release_date).dt.days / 7
    rdd_df['treatment'] = (rdd_df['date'] >= release_date).astype(int)
    rdd_df['interaction'] = rdd_df['time_from_cutoff'] * rdd_df['treatment']

    # OLSï¼ˆæœ€å°äºŒä¹—æ³•ï¼‰ã«ã‚ˆã‚‹å›å¸°ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ã¨å®Ÿè¡Œ
    Y = rdd_df[outcome_variable]
    X = rdd_df[['treatment', 'time_from_cutoff', 'interaction']]
    X = sm.add_constant(X)

    try:
        model = sm.OLS(Y, X).fit()
        print("\n[RDD Model Summary]")
        print(model.summary())

        # åˆ†æçµæœã®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
        plt.figure(figsize=(12, 8))
        plt.scatter(rdd_df['time_from_cutoff'], Y, alpha=0.5, label='Weekly SATD Rate')

        pred_df = rdd_df.copy().sort_values('time_from_cutoff')
        pred_vals = model.predict(sm.add_constant(pred_df[['treatment', 'time_from_cutoff', 'interaction']]))

        pre_cutoff = pred_df[pred_df['treatment'] == 0]
        post_cutoff = pred_df[pred_df['treatment'] == 1]

        plt.plot(pre_cutoff['time_from_cutoff'], pred_vals[pre_cutoff.index], color='blue', linewidth=3,
                 label='Fit (Before)')
        plt.plot(post_cutoff['time_from_cutoff'], pred_vals[post_cutoff.index], color='red', linewidth=3,
                 label='Fit (After)')

        plt.axvline(x=0, color='gray', linestyle='--', label=f'Cutoff: {release_date_str}')
        plt.title(f'RDD Analysis for {project_name}\n{outcome_variable} around {release_date_str} ({release_type})')
        plt.xlabel('Weeks from Release Cutoff')
        plt.ylabel(outcome_variable)
        plt.legend()
        plt.grid(True)

        # ã‚°ãƒ©ãƒ•ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        plot_dir = 'rdd_plots_per_release'
        os.makedirs(plot_dir, exist_ok=True)
        safe_project_name = project_name.replace(' ', '_').replace('.', '')
        plot_filename = f"{safe_project_name}_{release_date_str}_{outcome_variable}.png"
        plt.savefig(os.path.join(plot_dir, plot_filename))
        plt.close()
        print(f"RDD plot saved to {os.path.join(plot_dir, plot_filename)}")

        # çµæœã‚’è¾æ›¸å½¢å¼ã§è¿”ã™
        return {
            'project': project_name,
            'release_date': release_date_str,
            'release_type': release_type,
            'outcome': outcome_variable,
            'treatment_coef': model.params['treatment'],
            'p_value': model.pvalues['treatment'],
            'r_squared': model.rsquared
        }

    except Exception as e:
        print(f"An error occurred during RDD analysis for {release_date_str}: {e}")
        return None


def main():
    """
    ãƒ¡ã‚¤ãƒ³ã®å®Ÿè¡Œé–¢æ•°ã€‚å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€å…¨ãƒªãƒªãƒ¼ã‚¹ã«å¯¾ã—ã¦åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    """
    db_conn = None
    all_rdd_results = []

    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        db_conn = mysql.connector.connect(**DB_CONFIG)
        if db_conn.is_connected():
            print("âœ… Successfully connected to the database.")

            # è¨­å®šã•ã‚ŒãŸå…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒ«ãƒ¼ãƒ—
            for project in STUDY_PROJECTS:
                print(f"\n\n{'=' * 25} Starting Analysis for: {project['project_name']} {'=' * 25}")

                # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»æº–å‚™
                df = fetch_and_prepare_data(db_conn, project)

                if df is not None and not df.empty:
                    # åˆ†æå¯¾è±¡ã®ãƒªãƒªãƒ¼ã‚¹æ—¥ãƒªã‚¹ãƒˆã‚’å–å¾—
                    release_dates = generate_release_dates(project)
                    print(f"Found {len(release_dates)} major releases to analyze.")

                    # å„ãƒªãƒªãƒ¼ã‚¹æ—¥ã‚’ãƒ«ãƒ¼ãƒ—
                    for release_info in release_dates:
                        # ADDEDã¨REMOVEDã®ä¸¡æ–¹ã§åˆ†æ
                        for outcome in ['Normalized_ADDED', 'Normalized_REMOVED']:
                            result = perform_rdd_analysis_for_release(
                                df, project['project_name'], release_info, outcome, window_weeks=104
                            )
                            if result:
                                all_rdd_results.append(result)

    except Error as e:
        print(f"âŒ Error connecting to MySQL: {e}")
    finally:
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ‡æ–­ã¨çµæœã®ä¿å­˜
        if db_conn and db_conn.is_connected():
            db_conn.close()
            print("\nâœ… Database connection closed.")

        if all_rdd_results:
            summary_df = pd.DataFrame(all_rdd_results)
            print("\n\n" + "=" * 30 + " Final RDD Analysis Summary " + "=" * 30)
            print(summary_df)

            # æœ€çµ‚ã‚µãƒãƒªãƒ¼ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            summary_df.to_csv("final_rdd_summary_per_release.csv", index=False)
            print("\nâœ… Summary saved to final_rdd_summary_per_release.csv")
        else:
            print("\nNo RDD analysis was successfully completed.")


if __name__ == '__main__':
    main()